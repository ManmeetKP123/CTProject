{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ubc/ece/home/ra/other/manmeetp/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dicom2nifti\n",
    "import dicom2nifti.settings as settings\n",
    "import matplotlib.pyplot as plt \n",
    "from glob import glob\n",
    "import os\n",
    "import torchio as tio\n",
    "\n",
    "settings.disable_validate_slice_increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the pixel data in the dataset (261042 bytes) doesn't match the expected length (524288 bytes). The dataset may be corrupted or there may be an issue with the pixel data handler.\n"
     ]
    }
   ],
   "source": [
    "#converting dicom slices to nifti 3d volumes\n",
    "#storing the DICOM files in the .nii.gz format for easier image processing\n",
    "files_error = list()\n",
    "\n",
    "dicom_input = \"ordered_data/CT_Lymph_Nodes\"\n",
    "nifti_output = \"3D_volumes_NIfTI_images\"\n",
    "\n",
    "folder = glob(dicom_input + '/*')\n",
    "files_already_done = []\n",
    "# print(os.listdir(nifti_output))\n",
    "# print(folder)\n",
    "i = 0\n",
    "try:\n",
    "    for patient in folder:\n",
    "        name = patient.split(\"/\")[2]\n",
    "        file_name = str(name + \".nii.gz\")\n",
    "        if (file_name not in os.listdir(nifti_output)):\n",
    "            dicom2nifti.dicom_series_to_nifti(patient, os.path.join(nifti_output, name + \".nii.gz\"))\n",
    "        else: \n",
    "            files_already_done.append(name)\n",
    "        i += 1\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    files_error.append(name)\n",
    "    i += 1\n",
    "finally:\n",
    "    files_error.append(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydicom import dcmread\n",
    "dcm_file_path = \"ordered_data/CT_Lymph_Nodes/MED_LYMPH_087/09-14-2014-MEDLYMPH087-mediastinallymphnodes-32851/mediastinallymphnodes-64654/1-001.dcm\"\n",
    "ds = dcmread(dcm_file_path)\n",
    "for element in ds:\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scan(path):\n",
    "    slices = [pydicom.dcmread(path + ‘/’ + s) for s in               \n",
    "              os.listdir(path)]\n",
    "    slices = [s for s in slices if 'SliceLocation' in s]\n",
    "    slices.sort(key = lambda x: int(x.InstanceNumber))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] —   \n",
    "                          slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation — \n",
    "                      slices[1].SliceLocation)\n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "    return slices\n",
    "\n",
    "    \n",
    "def get_pixels_hu(scans):\n",
    "    image = np.stack([s.pixel_array for s in scans])\n",
    "    image = image.astype(np.int16)\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = scans[0].RescaleIntercept\n",
    "    slope = scans[0].RescaleSlope\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 313, 313, 574)\n",
      "(1, 128, 128, 574)\n",
      "ressssaaaampled\n",
      "(1, 450, 450, 746)\n",
      "(1, 128, 128, 746)\n",
      "ressssaaaampled\n",
      "(1, 295, 295, 709)\n",
      "(1, 128, 128, 709)\n",
      "ressssaaaampled\n",
      "(1, 347, 347, 783)\n",
      "(1, 128, 128, 783)\n",
      "ressssaaaampled\n",
      "(1, 469, 469, 671)\n",
      "(1, 128, 128, 671)\n",
      "ressssaaaampled\n",
      "(1, 450, 450, 696)\n",
      "(1, 128, 128, 696)\n",
      "ressssaaaampled\n",
      "(1, 240, 240, 636)\n",
      "(1, 128, 128, 636)\n",
      "ressssaaaampled\n",
      "(1, 489, 489, 696)\n",
      "(1, 128, 128, 696)\n",
      "ressssaaaampled\n",
      "(1, 379, 379, 524)\n",
      "(1, 128, 128, 524)\n",
      "ressssaaaampled\n",
      "(1, 254, 254, 666)\n",
      "(1, 128, 128, 666)\n",
      "ressssaaaampled\n",
      "(1, 308, 308, 666)\n",
      "(1, 128, 128, 666)\n",
      "ressssaaaampled\n",
      "(1, 287, 287, 661)\n",
      "(1, 128, 128, 661)\n",
      "ressssaaaampled\n",
      "(1, 226, 226, 827)\n",
      "(1, 128, 128, 827)\n",
      "ressssaaaampled\n",
      "(1, 254, 254, 771)\n",
      "(1, 128, 128, 771)\n",
      "ressssaaaampled\n",
      "(1, 240, 240, 752)\n",
      "(1, 128, 128, 752)\n",
      "ressssaaaampled\n",
      "(1, 313, 313, 816)\n",
      "(1, 128, 128, 816)\n",
      "ressssaaaampled\n",
      "(1, 226, 226, 830)\n",
      "(1, 128, 128, 830)\n",
      "ressssaaaampled\n",
      "(1, 283, 283, 715)\n",
      "(1, 128, 128, 715)\n",
      "ressssaaaampled\n",
      "(1, 443, 443, 691)\n",
      "(1, 128, 128, 691)\n",
      "ressssaaaampled\n",
      "(1, 414, 414, 858)\n",
      "(1, 128, 128, 858)\n",
      "ressssaaaampled\n",
      "(1, 372, 372, 3700)\n",
      "(1, 128, 128, 3700)\n",
      "ressssaaaampled\n",
      "(1, 268, 268, 636)\n",
      "(1, 128, 128, 636)\n",
      "ressssaaaampled\n",
      "(1, 489, 489, 966)\n",
      "(1, 128, 128, 966)\n",
      "ressssaaaampled\n",
      "(1, 310, 310, 627)\n",
      "(1, 128, 128, 627)\n",
      "ressssaaaampled\n",
      "(1, 313, 313, 651)\n",
      "(1, 128, 128, 651)\n",
      "ressssaaaampled\n",
      "(1, 475, 475, 702)\n",
      "(1, 128, 128, 702)\n",
      "ressssaaaampled\n",
      "(1, 228, 228, 598)\n",
      "(1, 128, 128, 598)\n",
      "ressssaaaampled\n",
      "(1, 240, 240, 661)\n",
      "(1, 128, 128, 661)\n",
      "ressssaaaampled\n",
      "(1, 450, 450, 746)\n",
      "(1, 128, 128, 746)\n",
      "ressssaaaampled\n",
      "(1, 489, 489, 908)\n",
      "(1, 128, 128, 908)\n",
      "ressssaaaampled\n",
      "(1, 240, 240, 636)\n",
      "(1, 128, 128, 636)\n",
      "ressssaaaampled\n",
      "(1, 421, 421, 683)\n",
      "(1, 128, 128, 683)\n",
      "ressssaaaampled\n",
      "(1, 489, 489, 654)\n",
      "(1, 128, 128, 654)\n",
      "ressssaaaampled\n",
      "(1, 353, 353, 691)\n",
      "(1, 128, 128, 691)\n",
      "ressssaaaampled\n",
      "(1, 240, 240, 765)\n",
      "(1, 128, 128, 765)\n",
      "ressssaaaampled\n",
      "(1, 342, 342, 677)\n",
      "(1, 128, 128, 677)\n",
      "ressssaaaampled\n",
      "(1, 301, 301, 643)\n",
      "(1, 128, 128, 643)\n",
      "ressssaaaampled\n",
      "(1, 401, 401, 815)\n",
      "(1, 128, 128, 815)\n",
      "ressssaaaampled\n",
      "(1, 318, 318, 651)\n",
      "(1, 128, 128, 651)\n",
      "ressssaaaampled\n",
      "(1, 345, 345, 411)\n",
      "(1, 128, 128, 411)\n",
      "ressssaaaampled\n",
      "(1, 450, 450, 718)\n",
      "(1, 128, 128, 718)\n",
      "ressssaaaampled\n",
      "(1, 313, 313, 641)\n",
      "(1, 128, 128, 641)\n",
      "ressssaaaampled\n",
      "(1, 310, 310, 645)\n",
      "(1, 128, 128, 645)\n",
      "ressssaaaampled\n",
      "(1, 313, 313, 748)\n",
      "(1, 128, 128, 748)\n",
      "ressssaaaampled\n",
      "(1, 373, 373, 666)\n",
      "(1, 128, 128, 666)\n",
      "ressssaaaampled\n",
      "(1, 450, 450, 718)\n",
      "(1, 128, 128, 718)\n",
      "ressssaaaampled\n",
      "(1, 489, 489, 642)\n",
      "(1, 128, 128, 642)\n",
      "ressssaaaampled\n",
      "(1, 414, 414, 631)\n",
      "(1, 128, 128, 631)\n",
      "ressssaaaampled\n",
      "(1, 277, 277, 721)\n",
      "(1, 128, 128, 721)\n",
      "ressssaaaampled\n",
      "(1, 316, 316, 721)\n",
      "(1, 128, 128, 721)\n",
      "ressssaaaampled\n"
     ]
    }
   ],
   "source": [
    "#now we apply isotropic resampling to the images to get a voxel spacing of 1mm in each direction\n",
    "\n",
    "import nibabel as nib\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "\n",
    "#THIS METHOD WILL OVERWRITE THE FILES IN DATA \n",
    "#the actual data\n",
    "image_folder = \"3D_volumes_NIfTI_images\"\n",
    "dest_input_folder = \"training_set/resampled_ALL_data\"\n",
    "\n",
    "for image in os.listdir(image_folder):\n",
    "    affine_matrix = nib.load(os.path.join(image_folder, image)).affine\n",
    "\n",
    "    input = tio.ScalarImage(os.path.join(image_folder, image), to_mni=affine_matrix)\n",
    "    transform = tio.Resample(1, pre_affine_name='to_mni')\n",
    "    isotropic_image = transform(input)\n",
    "    print(np.shape(isotropic_image))\n",
    "\n",
    "    #according to the paper a resolution of 128 x 128 x 144 was chosen \n",
    "    #but we will resample it to 128 x 128 x depth so that we can choose 128 slices after\n",
    "    padding = tio.Resample(target=(np.shape(isotropic_image)[2]/128, np.shape(isotropic_image)[2]/128, 1))\n",
    "    padded_image = padding(isotropic_image)\n",
    "    print(np.shape(padded_image))\n",
    "\n",
    "    if (os.path.isfile(os.path.join(dest_input_folder,  image))):\n",
    "        os.remove(os.path.join(dest_input_folder,  image))\n",
    "        print(\"file removed\")\n",
    "    tio.Image.save(padded_image, path=os.path.join(dest_input_folder,  image))\n",
    "    print(\"ressssaaaampled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(\"ordered_data/CT_Lymph_Nodes\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(files_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a3b8f5430dcba285e05c791357a5662af4e340364058ab0fc06e8662d8ba7a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
